{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## import the tools\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import laspy\n",
    "\n",
    "import torch\n",
    "## to find the neighbor points prediction\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## import the model tools\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_points3d.core.data_transform import MinPoints, XYZFeature, AddFeatsByKeys, GridSampling3D\n",
    "from torch_points3d.core.data_transform.features import AddOnes\n",
    "from torch_points3d.applications.pretrained_api import PretainedRegistry\n",
    "from torch_geometric.data import Batch\n",
    "from torch_points3d.metrics.confusion_matrix import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(src_points, candidates, k_neighbors=1):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "    tree = KDTree(candidates, leaf_size=20, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    closest = np.squeeze(indices)\n",
    "    return closest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str, data_path: str):\n",
    "    model = torch.load(model_path)\n",
    "    model['run_config']['data']['dataroot'] = data_path\n",
    "    # print(model['run_config'][\"data\"])\n",
    "    # model['run_config']['data']['path_to_model'] = \"/home/jf/Documents/msc/torch-3dpoints-powerline/models/preprocess_CNN/cnnStateDict.pth\"\n",
    "    torch.save(model, model_path)\n",
    "    # # transformer for non ones\n",
    "    # pos_z = [ \"pos_z\" ]\n",
    "    # list_add_to_x = [ True ]\n",
    "    # delete_feats = [ True ]\n",
    "    # first_subsampling = model['run_config'][\"data\"][\"first_subsampling\"]\n",
    "    # transform_test = Compose([MinPoints(512),\n",
    "    #                     XYZFeature(add_x=False, add_y=False, add_z= True),\n",
    "    #                     AddFeatsByKeys(list_add_to_x=list_add_to_x, feat_names= pos_z,delete_feats=delete_feats),\n",
    "    #                     GridSampling3D(mode='last', size=first_subsampling, quantize_coords=True)\n",
    "    #                     ])\n",
    "\n",
    "    # transformer for ones\n",
    "    pos_z = [ \"ones\" ]\n",
    "    list_add_to_x = [ True ]\n",
    "    delete_feats = [ True ]\n",
    "    first_subsampling = model['run_config'][\"data\"][\"first_subsampling\"]\n",
    "    input_nc_feats = [1]\n",
    "\n",
    "    transform_test = Compose([MinPoints(512),\n",
    "                     AddOnes(),\n",
    "                     AddFeatsByKeys(list_add_to_x=list_add_to_x, feat_names= pos_z,delete_feats=delete_feats, input_nc_feats=input_nc_feats),\n",
    "                     GridSampling3D(mode='last', size=first_subsampling, quantize_coords=True)\n",
    "                     ])\n",
    "    ### ['latest', 'loss_seg', 'acc', 'macc', 'miou']\n",
    "    model_pl = PretainedRegistry.from_file(model_path, weight_name=\"miou\").cuda()\n",
    "    return model_pl, transform_test, model['run_config']['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(room_info, model, filename, transform_test, predict_folder):\n",
    "    ## loop for every files\n",
    "    room_coord_mins = room_info['room_coord_min']\n",
    "    room_coord_scales = room_info['room_coord_scale']\n",
    "    files = list(glob.glob(predict_folder + f\"/*{filename}*cloud*pt\"))\n",
    "\n",
    "    pred_data = []\n",
    "\n",
    "    for file in files:\n",
    "        sample = os.path.join(predict_folder, file)\n",
    "        pt_data = torch.load(sample)\n",
    "        room_index = pt_data['room_idx']\n",
    "\n",
    "        room_coord_scale = room_coord_scales[room_index]\n",
    "        pos_ = pt_data['points']\n",
    "        point_in_original_las = pos_ * room_coord_scale + room_coord_mins[room_index]\n",
    "\n",
    "        data_s = transform_test(Batch(pos=torch.from_numpy(pos_).float()))\n",
    "        data_s.batch = torch.zeros(len(data_s.pos))\n",
    "        data_s.y = torch.zeros(data_s.pos.shape[0]).long()\n",
    "        index_to_nearst_neighbor = get_nearest_neighbors(pos_, data_s.pos)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            model.set_input(data_s, \"cuda\")\n",
    "            model.forward(data_s)\n",
    "        \n",
    "        pre = model.output.cpu().numpy()\n",
    "        m = torch.nn.functional.softmax(torch.tensor(pre), dim=1)\n",
    "        cla_pre = np.argmax(m, axis=1)\n",
    "        pre_ori = np.arange(len(pos_))\n",
    "        if len(pos_) == 1:\n",
    "            pre_ori[0] = cla_pre[0]\n",
    "        else:\n",
    "            for i in pre_ori:\n",
    "                pre_ori[i] = cla_pre[index_to_nearst_neighbor[i]]\n",
    "        combine_pre = np.column_stack((point_in_original_las, pre_ori.T))\n",
    "\n",
    "        pred_data.append(combine_pre)\n",
    "\n",
    "    pred_data = np.array([item for sublist in pred_data for item in sublist])\n",
    "\n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(pred_data, las_file, whole_las):\n",
    "    ## read original las file\n",
    "\n",
    "    powerline_pts = pred_data[np.where(pred_data[:,3] == 1)].copy()\n",
    "    powerline_pts_coord = powerline_pts[:,:-1].astype(np.int32) \n",
    "    # print(len(pred_data))\n",
    "    pred_data = np.unique(pred_data, axis=0)\n",
    "    # print(len(pred_data))\n",
    "\n",
    "    las_file_point_data = np.stack([las_file.X, las_file.Y, las_file.Z], axis=0).transpose((1, 0))\n",
    "    las_file_idx = get_nearest_neighbors(powerline_pts_coord, las_file_point_data)\n",
    "    pred = np.zeros(len(las_file_point_data))\n",
    "    las_file_label = las_file.classification \n",
    "    las_file_label = las_file_label==14 \n",
    "    pred[las_file_idx] = 1\n",
    "    pred = np.asarray(pred,dtype=np.int16)\n",
    "    las_file_label = np.asarray(las_file_label,dtype=np.int16)\n",
    "    # print(len(las_file_point_data))\n",
    "\n",
    "    cfm = ConfusionMatrix()\n",
    "    #Use as count_predicted_batch(true pred)\n",
    "    cfm.count_predicted_batch(las_file_label, pred)\n",
    "    las_file_metric_dict = {}\n",
    "\n",
    "    las_file_metric_dict[\"acc\"] = 100 * cfm.get_overall_accuracy()\n",
    "    las_file_metric_dict[\"macc\"] = 100 * cfm.get_mean_class_accuracy()\n",
    "    las_file_metric_dict[\"miou\"] = 100 * cfm.get_average_intersection_union()\n",
    "    las_file_metric_dict[\"miou_class\"] = {\n",
    "        i: \"{:.2f}\".format(100 * v)\n",
    "        for i, v in enumerate(cfm.get_intersection_union_per_class()[0])\n",
    "    }\n",
    "    las_file_metric_dict[\"precision\"] = cfm.get_confusion_matrix()[1][1]/(cfm.get_confusion_matrix()[1][1]+cfm.get_confusion_matrix()[0][1])\n",
    "    las_file_metric_dict[\"recall\"] = cfm.get_confusion_matrix()[1][1]/(cfm.get_confusion_matrix()[1][1]+cfm.get_confusion_matrix()[1][0])\n",
    "    las_file_metric_dict[\"cfm\"] = cfm.get_confusion_matrix()\n",
    "\n",
    "\n",
    "    whole_las_metric_dict = {}\n",
    "\n",
    "    return las_file_metric_dict, whole_las_metric_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "loading processed train split\n",
      "Total of 14594 samples in train set.\n",
      "loading processed val split\n",
      "Total of 815 samples in val set.\n",
      "loading processed test split\n",
      "Total of 1917 samples in test set.\n",
      "False\n",
      "64\n",
      "1\n",
      "343\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "128\n",
      "64\n",
      "1\n",
      "False\n",
      "64\n",
      "64\n",
      "8\n",
      "False\n",
      "128\n",
      "64\n",
      "27\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "256\n",
      "128\n",
      "1\n",
      "False\n",
      "128\n",
      "128\n",
      "8\n",
      "False\n",
      "256\n",
      "128\n",
      "27\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "512\n",
      "256\n",
      "1\n",
      "False\n",
      "256\n",
      "256\n",
      "8\n",
      "False\n",
      "512\n",
      "256\n",
      "27\n",
      "False\n",
      "512\n",
      "512\n",
      "27\n",
      "False\n",
      "512\n",
      "512\n",
      "27\n",
      "False\n",
      "512\n",
      "512\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-05-29 00:29:27,989 - model_checkpoint - Available weights : ['latest', 'loss_seg', 'acc', 'macc', 'miou', 'precision', 'recall']\n",
      "INFO - 2023-05-29 00:29:27,990 - model_checkpoint - Model loaded from SEUNet18.pt:best_miou.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "256\n",
      "512\n",
      "8\n",
      "False\n",
      "256\n",
      "512\n",
      "1\n",
      "False\n",
      "256\n",
      "512\n",
      "27\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "False\n",
      "256\n",
      "256\n",
      "27\n",
      "True\n",
      "128\n",
      "256\n",
      "8\n",
      "False\n",
      "128\n",
      "256\n",
      "1\n",
      "False\n",
      "128\n",
      "256\n",
      "27\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "False\n",
      "128\n",
      "128\n",
      "27\n",
      "True\n",
      "64\n",
      "128\n",
      "8\n",
      "False\n",
      "64\n",
      "128\n",
      "1\n",
      "False\n",
      "64\n",
      "128\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "True\n",
      "32\n",
      "64\n",
      "8\n",
      "False\n",
      "64\n",
      "96\n",
      "1\n",
      "False\n",
      "64\n",
      "96\n",
      "27\n",
      "False\n",
      "64\n",
      "64\n",
      "27\n",
      "False\n",
      "2\n",
      "64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jf/data\"\n",
    "raw_data_path = \"/home/jf/data/denmark/raw/\"\n",
    "root_path = \"/home/jf/Documents/msc/torch-3dpoints-powerline/\"\n",
    "model_folder = \"2023-05-22/20-40-06/\"\n",
    "model_name = \"SEUNet18.pt\"\n",
    "model_path = root_path+ \"outputs/\" + model_folder + model_name\n",
    "\n",
    "model, transform_test, config = load_model(model_path, data_path)\n",
    "\n",
    "## load transform pt pre\n",
    "processed_folder_name = config[\"processed_folder\"] \n",
    "data_root_path = os.path.join(config['dataroot'] , \"denmark\")\n",
    "processed_data_root_path = os.path.join(data_root_path, processed_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predecting on PUNKTSKY_00004_1km_6106_492\n",
      "4095\n",
      "Predecting on PUNKTSKY_00005_1km_6219_494\n",
      "4095\n",
      "Predecting on PUNKTSKY_00004_1km_6106_510\n",
      "4095\n",
      "Predecting on PUNKTSKY_00004_1km_6106_494\n",
      "4095\n",
      "Predecting on PUNKTSKY_00005_1km_6211_474\n",
      "4095\n",
      "Predecting on PUNKTSKY_00004_1km_6105_518\n",
      "4095\n",
      "Predecting on PUNKTSKY_00004_1km_6106_493\n",
      "4095\n"
     ]
    }
   ],
   "source": [
    "splits = [\"test\", \"val\", \"test\"]\n",
    "split_dict = {}\n",
    "for split in splits[:1]:\n",
    "    metric_dict = {}\n",
    "    if split == \"train\":\n",
    "        overlap = config[\"train_overlap\"]\n",
    "    if split == \"val\":\n",
    "        overlap = 0\n",
    "    if split == \"test\":\n",
    "        overlap = 0\n",
    "    predict_folder_name = f\"{split}_{overlap}_({config['block_size_x']}, {config['block_size_y']})\"\n",
    "    predict_folder = os.path.join(processed_data_root_path, predict_folder_name)\n",
    "    pre_trans_path = os.path.join(predict_folder, \"stats.pt\")\n",
    "    room_info = torch.load(pre_trans_path)\n",
    "    \n",
    "    files = room_info['room_names']\n",
    "    for filename in files:\n",
    "        print(f\"Predecting on {filename}\")\n",
    "        #the unprocessed file\n",
    "        # raw_file_path = os.path.join(raw_data_path,split,filename+\".laz\")\n",
    "        # raw_file = laspy.read(raw_file_path, laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "        #the file that the models sees\n",
    "        model_file_path = os.path.join(raw_data_path,split,\"NewLaz\",filename+\".laz\")\n",
    "        model_file = laspy.read(model_file_path, laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "\n",
    "        pred_data = predict(room_info, model, filename, transform_test, predict_folder)\n",
    "        model_las_metric_dict, whole_las_metric_dict = get_metrics(pred_data, model_file,\"\")#raw_file)\n",
    "        metric_dict[filename] = {\"model\":model_las_metric_dict, \"whole\":whole_las_metric_dict}\n",
    "    \n",
    "    split_dict[split] = metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#metric_dict = split_dict[\"train\"]\n",
    "mean_metric_dict = {}\n",
    "for key, metric_dict in split_dict.items():\n",
    "    split_model_dict = defaultdict(list)\n",
    "    split_whole_dict = defaultdict(list)\n",
    "    for filename, seen_metric_dicts in metric_dict.items():\n",
    "        # print(filename)\n",
    "        # print(seen_metric_dicts)\n",
    "        for split, file_metric_dict in seen_metric_dicts.items():\n",
    "            for metric_name, metric_value in file_metric_dict.items():\n",
    "                if split == \"model\":\n",
    "                    if metric_name != \"miou_class\":\n",
    "                        split_model_dict[metric_name].append(metric_value)\n",
    "                    else:\n",
    "                        for _class, value in metric_value.items():\n",
    "                            split_model_dict[f\"miou_{_class}\"].append(float(value))\n",
    "                else:\n",
    "                    if metric_name != \"miou_class\":\n",
    "                        split_whole_dict[metric_name].append(metric_value)\n",
    "                    else:\n",
    "                        for _class, value in metric_value.items():\n",
    "                            split_whole_dict[f\"miou_{_class}\"].append(float(value))\n",
    "\n",
    "    mean_dict = {}\n",
    "    for metric_key, metric_values in split_model_dict.items():\n",
    "        if metric_key!=\"cfm\":\n",
    "            mean = sum(metric_values) / len(metric_values)\n",
    "        else:\n",
    "            mean = np.add.reduce(metric_values)\n",
    "\n",
    "        mean_dict[metric_key] = mean\n",
    "    mean_metric_dict[key] = mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"PUNKTSKY_00004_1km_6105_518\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.77558040644318,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    761468,\n",
      "                    1\n",
      "                ],\n",
      "                [\n",
      "                    1767,\n",
      "                    24574\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 96.64584755258502,\n",
      "            \"miou\": 96.52832080520561,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.77\",\n",
      "                \"1\": \"93.29\"\n",
      "            },\n",
      "            \"precision\": 0.9999593082400814,\n",
      "            \"recall\": 0.9329182643027979\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    },\n",
      "    \"PUNKTSKY_00004_1km_6106_492\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.97342534389041,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    2084050,\n",
      "                    39\n",
      "                ],\n",
      "                [\n",
      "                    516,\n",
      "                    3851\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 94.09111838105903,\n",
      "            \"miou\": 93.68845943867798,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.97\",\n",
      "                \"1\": \"87.40\"\n",
      "            },\n",
      "            \"precision\": 0.989974293059126,\n",
      "            \"recall\": 0.8818410808335242\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    },\n",
      "    \"PUNKTSKY_00004_1km_6106_493\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.9521190072237,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    1360195,\n",
      "                    114\n",
      "                ],\n",
      "                [\n",
      "                    543,\n",
      "                    11300\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 97.70331631952307,\n",
      "            \"miou\": 97.22851705908164,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.95\",\n",
      "                \"1\": \"94.51\"\n",
      "            },\n",
      "            \"precision\": 0.9900122656386894,\n",
      "            \"recall\": 0.9541501308790002\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    },\n",
      "    \"PUNKTSKY_00004_1km_6106_494\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.95258556549338,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    1075105,\n",
      "                    218\n",
      "                ],\n",
      "                [\n",
      "                    295,\n",
      "                    6331\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 97.76378442837503,\n",
      "            \"miou\": 96.2283459446873,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.95\",\n",
      "                \"1\": \"92.50\"\n",
      "            },\n",
      "            \"precision\": 0.9667124751870515,\n",
      "            \"recall\": 0.9554784183519469\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    },\n",
      "    \"PUNKTSKY_00004_1km_6106_510\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.98162876539651,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    1055941,\n",
      "                    4\n",
      "                ],\n",
      "                [\n",
      "                    191,\n",
      "                    5306\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 98.26249933550818,\n",
      "            \"miou\": 98.21836421703632,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.98\",\n",
      "                \"1\": \"96.46\"\n",
      "            },\n",
      "            \"precision\": 0.9992467043314501,\n",
      "            \"recall\": 0.9652537747862471\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    },\n",
      "    \"PUNKTSKY_00005_1km_6211_474\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.89943329998195,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    2893744,\n",
      "                    1301\n",
      "                ],\n",
      "                [\n",
      "                    1642,\n",
      "                    29729\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 97.36046385612156,\n",
      "            \"miou\": 95.44534507350284,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.90\",\n",
      "                \"1\": \"90.99\"\n",
      "            },\n",
      "            \"precision\": 0.9580728327425072,\n",
      "            \"recall\": 0.9476586656466163\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    },\n",
      "    \"PUNKTSKY_00005_1km_6219_494\": {\n",
      "        \"model\": {\n",
      "            \"acc\": 99.95956156359337,\n",
      "            \"cfm\": [\n",
      "                [\n",
      "                    3038439,\n",
      "                    113\n",
      "                ],\n",
      "                [\n",
      "                    1123,\n",
      "                    16823\n",
      "                ]\n",
      "            ],\n",
      "            \"macc\": 96.86930962443239,\n",
      "            \"miou\": 96.55755348279158,\n",
      "            \"miou_class\": {\n",
      "                \"0\": \"99.96\",\n",
      "                \"1\": \"93.16\"\n",
      "            },\n",
      "            \"precision\": 0.9933278223901748,\n",
      "            \"recall\": 0.9374233812548758\n",
      "        },\n",
      "        \"whole\": {}\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(metric_dict,sort_keys=True, indent=4,cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"1abc_{model_name.split('.')[0]}_20_split.json\", \"w\") as fp:\n",
    "    json.dump(split_dict[\"test\"],fp, cls=NumpyEncoder)\n",
    "\n",
    "with open(f\"1abc_{model_name.split('.')[0]}_20_mean.json\", \"w\") as fp:\n",
    "    json.dump(mean_metric_dict[\"test\"],fp,cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'PUNKTSKY_00004_1km_6106_492': {'model': {'acc': 99.97342534389041,\n",
       "    'macc': 94.09111838105903,\n",
       "    'miou': 93.68845943867798,\n",
       "    'miou_class': {0: '99.97', 1: '87.40'},\n",
       "    'precision': 0.989974293059126,\n",
       "    'recall': 0.8818410808335242,\n",
       "    'cfm': array([[2084050,      39],\n",
       "           [    516,    3851]])},\n",
       "   'whole': {}},\n",
       "  'PUNKTSKY_00005_1km_6219_494': {'model': {'acc': 99.95956156359337,\n",
       "    'macc': 96.86930962443239,\n",
       "    'miou': 96.55755348279158,\n",
       "    'miou_class': {0: '99.96', 1: '93.16'},\n",
       "    'precision': 0.9933278223901748,\n",
       "    'recall': 0.9374233812548758,\n",
       "    'cfm': array([[3038439,     113],\n",
       "           [   1123,   16823]])},\n",
       "   'whole': {}},\n",
       "  'PUNKTSKY_00004_1km_6106_510': {'model': {'acc': 99.98162876539651,\n",
       "    'macc': 98.26249933550818,\n",
       "    'miou': 98.21836421703632,\n",
       "    'miou_class': {0: '99.98', 1: '96.46'},\n",
       "    'precision': 0.9992467043314501,\n",
       "    'recall': 0.9652537747862471,\n",
       "    'cfm': array([[1055941,       4],\n",
       "           [    191,    5306]])},\n",
       "   'whole': {}},\n",
       "  'PUNKTSKY_00004_1km_6106_494': {'model': {'acc': 99.95258556549338,\n",
       "    'macc': 97.76378442837503,\n",
       "    'miou': 96.2283459446873,\n",
       "    'miou_class': {0: '99.95', 1: '92.50'},\n",
       "    'precision': 0.9667124751870515,\n",
       "    'recall': 0.9554784183519469,\n",
       "    'cfm': array([[1075105,     218],\n",
       "           [    295,    6331]])},\n",
       "   'whole': {}},\n",
       "  'PUNKTSKY_00005_1km_6211_474': {'model': {'acc': 99.89943329998195,\n",
       "    'macc': 97.36046385612156,\n",
       "    'miou': 95.44534507350284,\n",
       "    'miou_class': {0: '99.90', 1: '90.99'},\n",
       "    'precision': 0.9580728327425072,\n",
       "    'recall': 0.9476586656466163,\n",
       "    'cfm': array([[2893744,    1301],\n",
       "           [   1642,   29729]])},\n",
       "   'whole': {}},\n",
       "  'PUNKTSKY_00004_1km_6105_518': {'model': {'acc': 99.77558040644318,\n",
       "    'macc': 96.64584755258502,\n",
       "    'miou': 96.52832080520561,\n",
       "    'miou_class': {0: '99.77', 1: '93.29'},\n",
       "    'precision': 0.9999593082400814,\n",
       "    'recall': 0.9329182643027979,\n",
       "    'cfm': array([[761468,      1],\n",
       "           [  1767,  24574]])},\n",
       "   'whole': {}},\n",
       "  'PUNKTSKY_00004_1km_6106_493': {'model': {'acc': 99.9521190072237,\n",
       "    'macc': 97.70331631952307,\n",
       "    'miou': 97.22851705908164,\n",
       "    'miou_class': {0: '99.95', 1: '94.51'},\n",
       "    'precision': 0.9900122656386894,\n",
       "    'recall': 0.9541501308790002,\n",
       "    'cfm': array([[1360195,     114],\n",
       "           [    543,   11300]])},\n",
       "   'whole': {}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'acc': 99.92776199314608,\n",
       "  'macc': 96.95661992822919,\n",
       "  'miou': 96.27070086014045,\n",
       "  'miou_0': 99.92571428571429,\n",
       "  'miou_1': 92.61571428571428,\n",
       "  'precision': 0.9853293859412974,\n",
       "  'recall': 0.9392462451507156,\n",
       "  'cfm': array([[12268942,     1790],\n",
       "         [    6077,    97914]])}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bfe5fc19ee440272b50e27189dca9d766ee16bd940e6c96fe401988e2293299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
