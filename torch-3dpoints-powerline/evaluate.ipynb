{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b8a0dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "## import the tools\n",
    "import torch\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors as NN\n",
    "import glob\n",
    "import pandas as pd\n",
    "import ipdb\n",
    "import laspy\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76970f59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## import the model tools\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_points3d.core.data_transform import GridSampling3D, MinPoints, XYZFeature, AddFeatsByKeys\n",
    "from torch_points3d.applications.pretrained_api import PretainedRegistry\n",
    "from torch_geometric.data import Batch,Dataset, Data ,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38aebf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1341bddf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading processed train split\n",
      "Total of 135 samples in train set.\n",
      "loading processed test split\n",
      "Total of 154 samples in test set.\n"
     ]
    }
   ],
   "source": [
    "## Load Powerline Model and change config\n",
    "pl_models_path = \"SEUNet18.pt\"\n",
    "model = torch.load(pl_models_path)\n",
    "model['run_config']['data']['dataroot'] = '/home/frederik/data/'\n",
    "torch.save(model, \"SEUNet18_modified.pt\")\n",
    "model_pl = PretainedRegistry.from_file(\"SEUNet18_modified\").cuda()\n",
    "\n",
    "## transformer\n",
    "pos_z = [ \"pos_z\" ]\n",
    "list_add_to_x = [ True ]\n",
    "delete_feats = [ True ]\n",
    "lparams = ['512']\n",
    "first_subsampling = model['run_config']['data']['first_subsampling']\n",
    "\n",
    "transform_test = Compose([MinPoints(512),\n",
    "                     XYZFeature(add_x=False, add_y=False, add_z= True),\n",
    "                     AddFeatsByKeys(list_add_to_x=list_add_to_x, feat_names= pos_z,delete_feats=delete_feats),\n",
    "                     GridSampling3D(mode='last', size=first_subsampling, quantize_coords=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89faedf7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## to find the neighbor points prediction\n",
    "from sklearn.neighbors import BallTree, KDTree\n",
    "import numpy as np\n",
    "def get_nearest(src_points, candidates, k_neighbors=1):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "    # src : whole gt points in a file \n",
    "    tree = KDTree(candidates, leaf_size=20, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    closest = np.squeeze(indices)\n",
    "    closest_dist = distances\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b2ee5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pl = PretainedRegistry.from_file(\"SEUNet18_modified\").cuda()\n",
    "#PretainedRegistry.from_pretrained(model_tag, download=True, out_file=None, weight_name=\"latest\", mock_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35051b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f366fb27",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Process with the normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465bd2ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## load test pt with normalized\n",
    "\n",
    "## load transform pt pre\n",
    "# root_path = \"/home/dmn774/data/Deep1/SegmentationDenmark/Lidar_tiles_KU/Powerlines/denmark/processed/\"\n",
    "# root_path = \"/home/dmn774/data/Deep1/SegmentationDenmark/Lidar_tiles_KU/Powerlines/test_some/denmark/processed/\"\n",
    "\n",
    "process_file_name_path = test_fold + \"/processed_file_names.pt\"\n",
    "vis_out_folder = data_root_path + 'vis/'\n",
    "\n",
    "pre_transform = torch.load(pre_trans_path)\n",
    "process_file_name = torch.load(process_file_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89484585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop for every files\n",
    "## delete files\n",
    "count = 0\n",
    "global_z = pre_transform['global_z']\n",
    "# for i in range(count_list):\n",
    "room_names = pre_transform['room_names']\n",
    "room_coord_mins = pre_transform['room_coord_min']\n",
    "room_coord_maxs = pre_transform['room_coord_max']\n",
    "room_coord_scales = pre_transform['room_coord_scale']\n",
    "count = 0\n",
    "for file in glob.glob(test_fold + \"*_cloud*pt\"):\n",
    "#     print(file)\n",
    "    sample = os.path.join(test_fold, file)\n",
    "    pt_data = torch.load(sample)\n",
    "    room_index = pt_data['room_idx']\n",
    "    room_name = room_names[room_index]\n",
    "    vis_out = os.path.join(vis_out_folder, room_name)\n",
    "#     ipdb.set_trace()\n",
    "\n",
    "    room_coord_scale = room_coord_scales[room_index]\n",
    "    pos_ = pt_data['points']\n",
    "    pt_ori = pt_data['points'] * room_coord_scale + pt_data['coord_min']\n",
    "    \n",
    "    data_s = transform_test(Batch(pos=torch.from_numpy(pos_).float(), batch=torch.zeros(pos_.shape[0]).long()))\n",
    "    # data_s = transform_test(Batch(pos=torch.from_numpy(pos_).float(), batch=torch.zeros(1).long()))\n",
    "    data_s.y = torch.zeros(data_s.batch.shape).long()\n",
    "    f = get_nearest(pos_, data_s.pos)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_pl.set_input(data_s, \"cuda\")\n",
    "        model_pl.forward(data_s)\n",
    "    \n",
    "    pre = model_pl.output.cpu().numpy()\n",
    "    m= torch.nn.functional.softmax(torch.tensor(pre), dim=1)\n",
    "    cla_pre = np.argmax(m, axis=1)\n",
    "    pre_ori = np.arange(len(pos_))\n",
    "    for i in pre_ori:\n",
    "#         print(i)\n",
    "        pre_ori[i] = cla_pre[f[i]]\n",
    "    combine_pre = np.column_stack((pt_ori, pre_ori.T))\n",
    "#     import ipdb;ipdb.set_trace()\n",
    "    vis_out = vis_out_folder + room_name +'pre.txt'\n",
    "    if os.path.exists(vis_out):\n",
    "        file_save = open(vis_out, 'a')\n",
    "    else:\n",
    "        file_save = open(vis_out, 'w')\n",
    "\n",
    "    file_save = open(vis_out_folder + room_name +'pre.txt', 'a')\n",
    "    np.savetxt(file_save, combine_pre, fmt = '%1.5f')\n",
    "#     file_save.write(\"\\n\")    \n",
    "#     break\n",
    "print(\"save finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e07e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Simple vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2043fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## read path\n",
    "vis_out_folder\n",
    "pred_path = os.path.join(vis_out_folder, \"PUNKTSKY_00005_1km_6084_519pre.txt\")\n",
    "pred_data = pd.read_csv(pred_path, sep=\" \", header=None).values\n",
    "pred_data, pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20040075",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx = np.arange(len(pred_data))\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:30000]\n",
    "\n",
    "vmin = pred_data[idx, -1].min()\n",
    "vmax = pred_data[idx, -1].max()\n",
    "cm = plt.cm.get_cmap('RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51cda8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## vis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9dd340",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sc = plt.scatter(pred_data[idx, 0], pred_data[idx, 1], c =pred_data[idx, -1],\n",
    "                cmap=cm, vmin=vmin, vmax=vmax, s=5\n",
    "            )\n",
    "plt.colorbar(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e487b",
   "metadata": {},
   "source": [
    "### check the individual pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95df9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bc87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09acb17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### check the individual pt\n",
    "data_root_path = \"/home/frederik/data/denmark/processed_hough/\"\n",
    "test_fold = data_root_path + \"test_0_(0.1, 0.1)/\"\n",
    "pre_trans_path = test_fold + \"/stats.pt\"\n",
    "pre_transform = torch.load(pre_trans_path)\n",
    "\n",
    "# Define global variables\n",
    "global_z = pre_transform['global_z']\n",
    "room_names = pre_transform['room_names']\n",
    "room_coord_mins = pre_transform['room_coord_min']\n",
    "room_coord_maxs = pre_transform['room_coord_max']\n",
    "room_coord_scales = pre_transform['room_coord_scale']\n",
    "\n",
    "# Load 1 Sample\n",
    "onesample = r\"/home/frederik/data/denmark/processed_hough/test_0_(0.1, 0.1)/PUNKTSKY_00005_1km_6161_465_cloud_50.pt\"\n",
    "pt_data = torch.load(onesample)\n",
    "\n",
    "# Define Local Variables\n",
    "points = pt_data['points']\n",
    "room_coord_scale = room_coord_scales[pt_data['room_idx']]\n",
    "pt_ori = pt_data['points'] * room_coord_scale + pt_data['coord_min']\n",
    "\n",
    "# Transform data corresponding to the \n",
    "data_s = transform_test(Batch(pos=torch.from_numpy(points).float()))\n",
    "data_s.batch = torch.zeros(len(data_s.pos))\n",
    "data_s.y = torch.zeros(data_s.pos.shape[0]).long()\n",
    "\n",
    "# Apply Model\n",
    "with torch.no_grad():\n",
    "    model_pl.set_input(data_s, \"cuda\")\n",
    "    model_pl.forward(data_s)\n",
    "\n",
    "# Use scores\n",
    "scores = model_pl.output.cpu().numpy()\n",
    "probabilities = torch.nn.functional.softmax(torch.tensor(scores), dim=1)\n",
    "predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Map indexes from x,y,z to the voxelized data and their predictions\n",
    "indexes = get_nearest(points, data_s.pos)\n",
    "\n",
    "points_predictions = torch.tensor([predictions[index] for _, index in enumerate(indexes)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b59db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = np.array([[5.00069739, 2.00061773, 0.50123249]])\n",
    "\n",
    "# data_s = transform_test(Batch(pos=torch.from_numpy(points).float()))\n",
    "# data_s.batch = torch.zeros(len(data_s.pos))\n",
    "# data_s.y = torch.zeros(data_s.pos.shape[0]).long()\n",
    "\n",
    "\n",
    "# # Apply Model\n",
    "# with torch.no_grad():\n",
    "#     model_pl.set_input(data_s, \"cuda\")\n",
    "#     model_pl.forward(data_s)\n",
    "\n",
    "#f = get_nearest(points, data_s.pos)\n",
    "\n",
    "\n",
    "\n",
    "#print(f)\n",
    "#print(type(f))\n",
    "#print((f.size))\n",
    "#print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795106d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_pl.eval()\n",
    "points_list = []\n",
    "preds_list = []\n",
    "\n",
    "### check the individual pt\n",
    "data_root_path = \"/home/frederik/data/denmark/processed_hough/\"\n",
    "test_fold = data_root_path + \"test_0_(0.1, 0.1)/\"\n",
    "pre_trans_path = test_fold + \"/stats.pt\"\n",
    "pre_transform = torch.load(pre_trans_path)\n",
    "\n",
    "# Define global variables\n",
    "global_z = pre_transform['global_z']\n",
    "room_names = pre_transform['room_names']\n",
    "room_coord_mins = pre_transform['room_coord_min']\n",
    "room_coord_maxs = pre_transform['room_coord_max']\n",
    "room_coord_scales = pre_transform['room_coord_scale']\n",
    "\n",
    "for i in range(0, 79):\n",
    "    onesample = r\"/home/frederik/data/denmark/processed_hough/test_0_(0.1, 0.1)/\"+\"PUNKTSKY_00005_1km_6162_472_cloud_\"+str(i)+\".pt\"\n",
    "    pt_data = torch.load(onesample)\n",
    "    \n",
    "    # Define Local Variables\n",
    "    points = pt_data['points']\n",
    "    room_coord_scale = room_coord_scales[pt_data['room_idx']]\n",
    "    \n",
    "    pt_ori = points*(pt_data['coord_max']-pt_data['coord_min'])*np.array([0.1, 0.1, 1.0])+pt_data['coord_min']\n",
    "    \n",
    "    # Transform data corresponding to the \n",
    "    data_s = transform_test(Batch(pos=torch.from_numpy(points).float()))\n",
    "    data_s.batch = torch.zeros(len(data_s.pos))\n",
    "    data_s.y = torch.zeros(data_s.pos.shape[0]).long()\n",
    "    \n",
    "    # Apply Model\n",
    "    with torch.no_grad():\n",
    "        model_pl.set_input(data_s, \"cuda\")\n",
    "        model_pl.forward(data_s)\n",
    "\n",
    "    # Use scores\n",
    "    scores = model_pl.output.cpu().numpy()\n",
    "    probabilities = torch.nn.functional.softmax(torch.tensor(scores), dim=1)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    # Map indexes from x,y,z to the voxelized data and their predictions\n",
    "    indexes = get_nearest(points, data_s.pos)\n",
    "    \n",
    "    points_predictions = [predictions[index].numpy() for _, index in enumerate(indexes)]\n",
    "    \n",
    "    preds_list.append(points_predictions)\n",
    "    points_list.append(pt_ori)\n",
    "    \n",
    "preds_list = np.array([item for sublist in preds_list for item in sublist])\n",
    "points_list = np.array([item for sublist in points_list for item in sublist])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5989cfd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095\n"
     ]
    }
   ],
   "source": [
    "las = laspy.read(\"/home/frederik/data/denmark/raw/test/LazFilesWithHeightParam/PUNKTSKY_00005_1km_6162_472_hag_nn.laz\", laz_backend=laspy.compression.LazBackend.LazrsParallel)\n",
    "points_data = np.stack([las.X, las.Y, las.Z], axis=0).transpose((1, 0))\n",
    "\n",
    "las.add_extra_dim(laspy.ExtraBytesParams(\n",
    "    name=\"prediction\",\n",
    "    type=np.uint8,\n",
    "    description=\"The prediction of the model\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de9604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = get_nearest(points_list, points_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8e9c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46500001.0\n",
      "46599997.999929994\n",
      "616100000.0\n",
      "616199999.0\n",
      "1945.0\n",
      "12878.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(points_list[:,0]))\n",
    "print(np.max(points_list[:,0]))\n",
    "\n",
    "print(np.min(points_list[:,1]))\n",
    "print(np.max(points_list[:,1]))\n",
    "\n",
    "print(np.min(points_list[:,2]))\n",
    "print(np.max(points_list[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc78d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47200000\n",
      "47300000\n",
      "616200000\n",
      "616300000\n",
      "1579\n",
      "14758\n"
     ]
    }
   ],
   "source": [
    "print(np.min(points_data[:,0]))\n",
    "print(np.max(points_data[:,0]))\n",
    "\n",
    "print(np.min(points_data[:,1]))\n",
    "print(np.max(points_data[:,1]))\n",
    "\n",
    "print(np.min(points_data[:,2]))\n",
    "print(np.max(points_data[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4bb535",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_las_preds = np.zeros(len(las.prediction))\n",
    "for i, index in enumerate(indexes):\n",
    "    final_las_preds[index] = preds_list[i]\n",
    "las.prediction = final_las_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c006fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "powerline_las = las[las.prediction == 1]\n",
    "powerline_points_data = np.stack([powerline_las.X, powerline_las.Y, powerline_las.Z], axis=0).transpose((1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3baa4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = o3d.geometry.PointCloud()\n",
    "geom.points = o3d.utility.Vector3dVector(powerline_points_data)\n",
    "o3d.visualization.draw_geometries([geom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3b18ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "succesfully_predicted_powerline_points = np.sum((las.classification == 14) & (las.prediction == 1))\n",
    "percentage = succesfully_predicted_powerline_points/np.sum(las.classification == 14)\n",
    "\n",
    "print(succesfully_predicted_powerline_points)\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225225b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce3de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54353f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e139a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcbe8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b005903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bc130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273ea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
